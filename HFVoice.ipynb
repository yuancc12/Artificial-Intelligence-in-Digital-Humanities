{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 匯入模組\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai==0.28 in c:\\users\\soon yuan chi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.28.0)\n",
      "Requirement already satisfied: requests>=2.20 in c:\\users\\soon yuan chi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai==0.28) (2.32.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\soon yuan chi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai==0.28) (4.66.4)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\soon yuan chi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai==0.28) (3.10.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\soon yuan chi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.20->openai==0.28) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\soon yuan chi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.20->openai==0.28) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\soon yuan chi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.20->openai==0.28) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\soon yuan chi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.20->openai==0.28) (2024.2.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\soon yuan chi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp->openai==0.28) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\soon yuan chi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp->openai==0.28) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\soon yuan chi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp->openai==0.28) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\soon yuan chi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp->openai==0.28) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\soon yuan chi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp->openai==0.28) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\soon yuan chi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp->openai==0.28) (1.9.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\soon yuan chi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tqdm->openai==0.28) (0.4.6)\n",
      "Completed!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install flask --quiet\n",
    "!pip install flask-ngrok --quiet\n",
    "!pip install openai==0.28\n",
    "\n",
    "print(\"Completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline\n",
    "from datasets import load_dataset\n",
    "import openai\n",
    "import pandas\n",
    "import tempfile\n",
    "import os\n",
    "import subprocess  # 用來調用 ffmpeg 進行音頻轉換\n",
    "from flask import Flask, request, jsonify\n",
    "from linebot import LineBotApi, WebhookHandler\n",
    "from linebot.exceptions import InvalidSignatureError\n",
    "from linebot.models import MessageEvent, TextMessage, TextSendMessage, AudioMessage\n",
    "import speech_recognition as sr\n",
    "import dateparser\n",
    "from datetime import datetime\n",
    "import openpyxl\n",
    "from openpyxl import Workbook\n",
    "import schedule\n",
    "import time\n",
    "import uuid\n",
    "import threading\n",
    "from flask_ngrok import run_with_ngrok\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  LINE Messaging API 設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Soon Yuan Chi\\AppData\\Local\\Temp\\ipykernel_2628\\931214875.py:1: LineBotSdkDeprecatedIn30: Call to deprecated class LineBotApi. (Use v3 class; linebot.v3.<feature>. See https://github.com/line/line-bot-sdk-python/blob/master/README.rst for more details.) -- Deprecated since version 3.0.0.\n",
      "  line_bot_api = LineBotApi('C/umEAgfJUlS3pGC8SCci0JU9lfoOUswEcXOdYpu8m2YEc7HcaRSx1eR2W8gPk7PeTkzyAXJz2CmuL5/7vsk97np6IlagtcqmoyQ3YKG1LJUeRcQ40Qb34T7e2dHuSrGOKs+6T7Wsa6KdulP0CMkMQdB04t89/1O/w1cDnyilFU=')\n",
      "C:\\Users\\Soon Yuan Chi\\AppData\\Local\\Temp\\ipykernel_2628\\931214875.py:2: LineBotSdkDeprecatedIn30: Call to deprecated class WebhookHandler. (Use 'from linebot.v3.webhook import WebhookHandler' instead. See https://github.com/line/line-bot-sdk-python/blob/master/README.rst for more details.) -- Deprecated since version 3.0.0.\n",
      "  handler = WebhookHandler('c828c28a14105df51e05a56f6c19024f')\n"
     ]
    }
   ],
   "source": [
    "line_bot_api = LineBotApi('C/umEAgfJUlS3pGC8SCci0JU9lfoOUswEcXOdYpu8m2YEc7HcaRSx1eR2W8gPk7PeTkzyAXJz2CmuL5/7vsk97np6IlagtcqmoyQ3YKG1LJUeRcQ40Qb34T7e2dHuSrGOKs+6T7Wsa6KdulP0CMkMQdB04t89/1O/w1cDnyilFU=')\n",
    "handler = WebhookHandler('c828c28a14105df51e05a56f6c19024f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenAI key 設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI API Key\n",
    "openai.api_key = 'sk-5hNsRQJN7awwxDjNkkPOCzBM92Kzw89kDYCzET-q8tT3BlbkFJ5uwDgZ9rCGGX4OJl9Rg655_KQ4tJZQmHf0YRcRvWgA'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 初始化 Flask 和 LINE Bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = Flask(__name__) #app name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 接收 LINE 的 Webhook 事件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route(\"/\", methods=['POST'])\n",
    "def callback():\n",
    "    # 確認 LINE 的簽名是否正確\n",
    "    signature = request.headers['X-Line-Signature']\n",
    "    body = request.get_data(as_text=True)\n",
    "\n",
    "    try:\n",
    "        handler.handle(body, signature)\n",
    "    except InvalidSignatureError:\n",
    "        return jsonify({'message': 'Invalid signature'}), 400\n",
    "    return 'OK',200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 解析時間的函數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_time(user_input_time):\n",
    "    parsed_time = dateparser.parse(user_input_time)\n",
    "    if parsed_time:\n",
    "        return parsed_time.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    return datetime.now().strftime('%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 處理收到的文字訊息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_states = {}\n",
    "@handler.add(MessageEvent, message=TextMessage)\n",
    "def handle_text_message(event):\n",
    "    text = event.message.text\n",
    "    user_id = event.source.user_id\n",
    "    if text.startswith(\"會議回顧\"):\n",
    "        keyword = text.replace(\"會議回顧\", \"\").strip()\n",
    "        response_message = search_summary(keyword)\n",
    "        line_bot_api.reply_message(event.reply_token, TextSendMessage(text=response_message))\n",
    "    if user_states.get(user_id) == \"Reminders\":\n",
    "        formatted_time = parse_time(\"現在\")\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"你是一個有用的提醒功能機器人，幫助用戶記錄需提醒的事情\"},\n",
    "                {\"role\": \"user\", \"content\": f\"請把以下提醒的事項整理成Time和Content，時間格式為 YYYY-MM-DD HH:MM，並以Database語法存入，只需要寫語法就好，不需要額外補充而且時間一定要準確：現在時間是：{formatted_time},内容是{text}\"}\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        response_text = response['choices'][0]['message']['content']\n",
    "        #line_bot_api.reply_message(event.reply_token, TextSendMessage(text=response_text))\n",
    "        # 保存提醒事項和轉換文本到 Excel\n",
    "        response_message = handle_transcript_and_reminder(user_id, response_text, text)\n",
    "        line_bot_api.reply_message(event.reply_token, TextSendMessage(text=response_message))\n",
    "        user_states[user_id] = \"\"\n",
    "\n",
    "    elif text == \"請輸入會議音檔\" and user_states.get(user_id) not in [\"Recording\", \"Reminders\",\"Summary_check\"]:\n",
    "        user_states[user_id] = \"Recording\"\n",
    "\n",
    "    elif text == \"請輸入需提醒事項\" and user_states.get(user_id) not in [\"Recording\", \"Reminders\",\"Summary_check\"]:\n",
    "        user_states[user_id] = \"Reminders\"\n",
    "    elif text == \"會議回顧\" and user_states.get(user_id) not in [\"Recording\", \"Reminders\",\"Summary_check\"]:\n",
    "        print('會議回顧中')\n",
    "        user_states[user_id] = \"Summary_check\"\n",
    "\n",
    "def summarize_with_openai(transcript):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"你是一個有用的會議記錄助手，幫助用戶開會的重點進行記錄，列點給我，不要多說別的東西。\"},\n",
    "            {\"role\": \"user\", \"content\": f\"請總結以下文本的重點：{transcript}\"}\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    return response['choices'][0]['message']['content']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 處理音檔"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@handler.add(MessageEvent, message=AudioMessage)\n",
    "def handle_audio_message(event):\n",
    "    user_id = event.source.user_id\n",
    "    message_id = event.message.id\n",
    "    message_content = line_bot_api.get_message_content(message_id)\n",
    "\n",
    "\n",
    "    # 保存音频到本地\n",
    "    current_directory = os.getcwd()\n",
    "    audio_path = os.path.join(current_directory, f'audio_file_{uuid.uuid4()}.m4a')\n",
    "\n",
    "    # 將音檔內容寫入指定位置\n",
    "    with open(audio_path, 'wb') as f:\n",
    "      f.write(message_content.content)\n",
    "    try:\n",
    "        # 將 .m4a 文件轉換為 .wav 文件\n",
    "        wav_path = convert_to_wav(audio_path)\n",
    "        # 使用本地語音轉文字方法將語音轉為文本\n",
    "        transcript = changetotext(wav_path)\n",
    "        # 根據用戶狀態進行相應處理\n",
    "        if user_states.get(user_id) == \"Recording\":\n",
    "            summary = summarize_with_openai(transcript)\n",
    "            # 保存摘要到 Excel 文件\n",
    "            #save_summary_to_excel(user_id, summary)\n",
    "            print('已成功存到資料庫')\n",
    "            line_bot_api.reply_message(event.reply_token, TextSendMessage(text=summary))\n",
    "        elif user_states.get(user_id) == \"Reminders\":\n",
    "            formatted_time = parse_time(\"現在\")\n",
    "            response = openai.ChatCompletion.create(\n",
    "                model=\"gpt-3.5-turbo\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"你是一個有用的提醒功能機器人，幫助用戶記錄需提醒的事情\"},\n",
    "                    {\"role\": \"user\", \"content\": f\"請把以下提醒的事項整理成Time和Content，時間格式為 YYYY-MM-DD HH:MM，並以Database語法存入，只需要寫語法就好，不需要額外補充而且時間一定要準確：現在時間是：{formatted_time},内容是{transcript}\"}\n",
    "                ]\n",
    "            )\n",
    "            response_text = response['choices'][0]['message']['content']\n",
    "            #line_bot_api.reply_message(event.reply_token, TextSendMessage(text=response_text))\n",
    "            response_message = handle_transcript_and_reminder(user_id, response_text)\n",
    "            line_bot_api.reply_message(event.reply_token, TextSendMessage(text=response_message))\n",
    "        #elif user_states.get(user_id) == \"Summary_check\":\n",
    "         #   search_summary(event)\n",
    "        user_states[user_id] = \"\"\n",
    "    except Exception as e:\n",
    "        line_bot_api.reply_message(event.reply_token, TextSendMessage(text=f\"抱歉，無法處理您的錄音。錯誤信息: {str(e)}\"))\n",
    "\n",
    "# 將 .m4a 轉換為 .wav 的函數\n",
    "def convert_to_wav(audio_path):\n",
    "    wav_path = audio_path.replace('.m4a', '.wav')\n",
    "    print(f\"Audio saved at: {audio_path}\")\n",
    "    print(f\"Audio saved at: {wav_path}\")\n",
    "    ffmpeg_path = r\"C:\\ffmpeg\\bin\\ffmpeg.exe\"\n",
    "    try:\n",
    "        print(\"開始轉換音頻...\")\n",
    "        result = subprocess.run([\"ffmpeg\", \"-i\", wav_path, \"-f\", \"segment\", \"-segment_time\", \"30\", \"output_%03d.wav\"])\n",
    "        if result.returncode != 0:\n",
    "            raise Exception(f\"音頻轉換失敗: {result.stderr}\")\n",
    "        print(\"轉換成功\")\n",
    "        return wav_path\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        raise Exception(f\"音頻轉換失敗: {e}\")\n",
    "\n",
    "def changetotext(wav_path):\n",
    "    device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "    torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
    "\n",
    "    model_id = \"openai/whisper-large-v3-turbo\"\n",
    "\n",
    "    model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
    "        model_id, torch_dtype=torch_dtype, low_cpu_mem_usage=True, use_safetensors=True\n",
    "    )\n",
    "    model.to(device)\n",
    "\n",
    "    processor = AutoProcessor.from_pretrained(model_id)\n",
    "\n",
    "    pipe = pipeline(\n",
    "        \"automatic-speech-recognition\",\n",
    "        model=model,\n",
    "        tokenizer=processor.tokenizer,\n",
    "        feature_extractor=processor.feature_extractor,\n",
    "        torch_dtype=torch_dtype,\n",
    "        device=device,\n",
    "        batch_size=16\n",
    "    )\n",
    "\n",
    "    # 步驟 1: 分割音訊檔案\n",
    "    def split_audio(wav_path, segment_length=30):\n",
    "        output_dir = \"audio_segments\"\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        subprocess.run([\n",
    "            \"ffmpeg\", \"-i\", wav_path,\n",
    "            \"-f\", \"segment\",\n",
    "            \"-segment_time\", str(segment_length),\n",
    "            os.path.join(output_dir, \"segment_%03d.wav\")\n",
    "        ])\n",
    "        return [os.path.join(output_dir, f) for f in sorted(os.listdir(output_dir)) if f.endswith(\".wav\")]\n",
    "\n",
    "    # 步驟 2: 定義轉錄單個音訊片段的函數\n",
    "    def transcribe_segment(segment_path):\n",
    "        result = pipe(segment_path, generate_kwargs={\"language\": \"Chinese\"})\n",
    "        return result[\"text\"] if \"text\" in result else \"\"\n",
    "    \n",
    "    # 步驟 3: 並行處理所有片段\n",
    "    def transcribe_all_segments(segments, chunk_size=4):\n",
    "        all_transcripts = []\n",
    "        with ThreadPoolExecutor(max_workers=chunk_size) as executor:\n",
    "            results = list(executor.map(transcribe_segment, segments))\n",
    "        all_transcripts.extend(results)\n",
    "        return \" \".join(all_transcripts)\n",
    "\n",
    "    # 嘗試進行轉錄\n",
    "    segments=split_audio(wav_path)\n",
    "    transcript = transcribe_all_segments(segments, chunk_size=4)  # 並行處理每段並合併結果\n",
    "    \n",
    "    if not transcript:\n",
    "        print(\"轉錄失敗，無法取得文本\")\n",
    "        return \"轉錄失敗，無法取得文本\"  # 返回空字串或其他預設值避免錯誤\n",
    "\n",
    "    print(\"Transcript: \" + transcript)\n",
    "    return transcript\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定期檢查提醒"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_reminders():\n",
    "    excel_file_path = 'reminders_database.xlsx'\n",
    "    workbook = openpyxl.load_workbook(excel_file_path)\n",
    "    sheet = workbook.active\n",
    "\n",
    "    # 獲取當前時間\n",
    "    current_time = datetime.now().strftime('%Y-%m-%d %H:%M')\n",
    "\n",
    "     # 遍歷表格，檢查時間是否到達\n",
    "    for row in sheet.iter_rows(min_row=2, values_only=True):  # 從第二行開始，忽略標題行\n",
    "        user_id, reminder_time, reminder_content = row[:3]  # 根據新順序提取 user_id、時間和內容\n",
    "        if reminder_time == current_time:\n",
    "            # 發送提醒消息，確保 user_id 有效\n",
    "            if user_id:\n",
    "                line_bot_api.push_message(user_id, TextSendMessage(text=f\"提醒時間到！內容是: {reminder_content}\"))\n",
    "            else:\n",
    "                print(f\"無效的 user_id，無法發送提醒給: {reminder_content}\")\n",
    "\n",
    "# 開始一個定期執行的任務來檢查提醒\n",
    "def start_scheduler():\n",
    "    schedule.every(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 啟動 Flask 應用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [01/Nov/2024 21:42:00] \"POST / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [01/Nov/2024 21:42:11] \"POST / HTTP/1.1\" 200 -\n",
      "C:\\Users\\Soon Yuan Chi\\AppData\\Local\\Temp\\ipykernel_2628\\806155468.py:5: LineBotSdkDeprecatedIn30: Call to deprecated method get_message_content. (Use 'from linebot.v3.messaging import MessagingApiBlob' and 'MessagingApiBlob(...).get_message_content(...)' instead. See https://github.com/line/line-bot-sdk-python/blob/master/README.rst for more details.) -- Deprecated since version 3.0.0.\n",
      "  message_content = line_bot_api.get_message_content(message_id)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio saved at: c:\\Users\\Soon Yuan Chi\\OneDrive\\Desktop\\作業完成區\\大四上\\數位人文的人工智慧\\期末專題\\audio_file_aa4664a5-0f18-42c7-b4b4-d44419d8a58c.m4a\n",
      "Audio saved at: c:\\Users\\Soon Yuan Chi\\OneDrive\\Desktop\\作業完成區\\大四上\\數位人文的人工智慧\\期末專題\\audio_file_aa4664a5-0f18-42c7-b4b4-d44419d8a58c.wav\n",
      "開始轉換音頻...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Soon Yuan Chi\\AppData\\Local\\Temp\\ipykernel_2628\\806155468.py:44: LineBotSdkDeprecatedIn30: Call to deprecated method reply_message. (Use 'from linebot.v3.messaging import MessagingApi' and 'MessagingApi(...).reply_message(...)' instead. See https://github.com/line/line-bot-sdk-python/blob/master/README.rst for more details.) -- Deprecated since version 3.0.0.\n",
      "  line_bot_api.reply_message(event.reply_token, TextSendMessage(text=f\"抱歉，無法處理您的錄音。錯誤信息: {str(e)}\"))\n",
      "127.0.0.1 - - [01/Nov/2024 21:42:57] \"POST / HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio saved at: c:\\Users\\Soon Yuan Chi\\OneDrive\\Desktop\\作業完成區\\大四上\\數位人文的人工智慧\\期末專題\\audio_file_252154d0-f842-4e09-8e63-a9bfb7af17b1.m4a\n",
      "Audio saved at: c:\\Users\\Soon Yuan Chi\\OneDrive\\Desktop\\作業完成區\\大四上\\數位人文的人工智慧\\期末專題\\audio_file_252154d0-f842-4e09-8e63-a9bfb7af17b1.wav\n",
      "開始轉換音頻...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [01/Nov/2024 21:43:18] \"POST / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [01/Nov/2024 21:44:56] \"POST / HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio saved at: c:\\Users\\Soon Yuan Chi\\OneDrive\\Desktop\\作業完成區\\大四上\\數位人文的人工智慧\\期末專題\\audio_file_c7c1eab0-9f70-4238-b424-0429ea5c737f.m4a\n",
      "Audio saved at: c:\\Users\\Soon Yuan Chi\\OneDrive\\Desktop\\作業完成區\\大四上\\數位人文的人工智慧\\期末專題\\audio_file_c7c1eab0-9f70-4238-b424-0429ea5c737f.wav\n",
      "開始轉換音頻...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [01/Nov/2024 21:46:03] \"POST / HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    app.run(port=5000, debug=True, use_reloader=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
