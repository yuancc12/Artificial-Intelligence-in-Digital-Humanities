import os
import requests
from flask import Flask, request, abort
from linebot.v3.messaging import MessagingApi, Configuration
from linebot.v3.webhook import WebhookHandler
from linebot.exceptions import InvalidSignatureError
from linebot.models import MessageEvent, AudioMessage, TextSendMessage
import torch
from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline, AutoModelForCausalLM, AutoTokenizer
from dotenv import load_dotenv

# Load environment variables from a .env file
load_dotenv()

app = Flask(__name__)

# LINE Bot credentials
LINE_CHANNEL_ACCESS_TOKEN = 'Line Api key'
LINE_CHANNEL_SECRET = 'Line Secret'
HF_AUTH_TOKEN = "請輸入HF Token"

# Configuration for LINE Bot
configuration = Configuration(access_token=LINE_CHANNEL_ACCESS_TOKEN)
line_bot_api = MessagingApi(configuration)
handler = WebhookHandler(channel_secret=LINE_CHANNEL_SECRET)

# Load the speech recognition model
device = "cuda:0" if torch.cuda.is_available() else "cpu"
torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32

model_id = "openai/whisper-large-v3-turbo"
model = AutoModelForSpeechSeq2Seq.from_pretrained(
    model_id, torch_dtype=torch_dtype, low_cpu_mem_usage=True, use_safetensors=True
)
model.to(device)

processor = AutoProcessor.from_pretrained(model_id)

speech_recognition_pipe = pipeline(
    "automatic-speech-recognition",
    model=model,
    tokenizer=processor.tokenizer,
    feature_extractor=processor.feature_extractor,
    torch_dtype=torch_dtype,
    device=device,
)

# Load the TAIDE chat model for summarization
chat_model_id = "taide/TAIDE-LX-7B-Chat"
tokenizer = AutoTokenizer.from_pretrained(chat_model_id, use_fast=False, use_auth_token=HF_AUTH_TOKEN)
chat_model = AutoModelForCausalLM.from_pretrained(chat_model_id, use_auth_token=HF_AUTH_TOKEN)
chat_pipe = pipeline("text-generation", model=chat_model, tokenizer=tokenizer, device=device)

# Webhook route
@app.route("/callback", methods=['POST'])
def callback():
    signature = request.headers['X-Line-Signature']
    body = request.get_data(as_text=True)

    try:
        handler.handle(body, signature)
    except InvalidSignatureError:
        abort(400)

    return 'OK'

# Handling audio messages
@handler.add(MessageEvent, message=AudioMessage)
def handle_audio_message(event):
    try:
        # Get audio content from LINE server
        message_content = line_bot_api.get_message_content(event.message.id)
        audio_file_path = "audio.m4a"
        with open(audio_file_path, 'wb') as f:
            for chunk in message_content.iter_content():
                f.write(chunk)

        # Load the audio and perform speech recognition
        result = speech_recognition_pipe(audio_file_path)
        transcription = result["text"]

        # Create the chat prompt
        chat = [
            {"role": "system", "content": "你是個文書記錄機器人，負責整理摘要"},
            {"role": "user", "content": transcription},
        ]
        prompt = tokenizer.apply_chat_template(chat)

        # Generate summary from transcription using chat model
        summary = chat_pipe(prompt, max_length=150, num_return_sequences=1)[0]['generated_text']

        # Send summary back to user
        line_bot_api.reply_message(
            event.reply_token,
            TextSendMessage(text=summary)
        )

    except Exception as e:
        # Send an error message back to the user
        line_bot_api.reply_message(
            event.reply_token,
            TextSendMessage(text=f"An error occurred: {str(e)}")
        )

if __name__ == "__main__":
    app.run(port=5000, debug=True)
