import openai
import tempfile
import os
import subprocess  # 用來調用 ffmpeg 進行音頻轉換
from flask import Flask, request, jsonify
from linebot import LineBotApi, WebhookHandler
from linebot.exceptions import InvalidSignatureError
from linebot.models import MessageEvent, TextMessage, TextSendMessage, AudioMessage
import speech_recognition as sr
import dateparser
from datetime import datetime

# OpenAI API Key
openai.api_key = 'Open API key'

# 設置環境變量禁用 oneDNN 優化（可選）
os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'

# 初始化 Flask 和 LINE Bot
app = Flask(__name__)

# LINE Messaging API 設定
line_bot_api = LineBotApi('LineAPI key')
handler = WebhookHandler('Line Secret')

# 用戶狀態字典
user_states = {}

# 解析時間的函數
def parse_time(user_input_time):
    parsed_time = dateparser.parse(user_input_time)
    if parsed_time:
        return parsed_time.strftime('%Y-%m-%d %H:%M:%S')
    return datetime.now().strftime('%Y-%m-%d %H:%M:%S')

# 接收 LINE 的 Webhook 事件
@app.route("/", methods=['POST'])
def callback():
    # 確認 LINE 的簽名是否正確
    signature = request.headers['X-Line-Signature']
    body = request.get_data(as_text=True)

    try:
        handler.handle(body, signature)
    except InvalidSignatureError:
        return jsonify({'message': 'Invalid signature'}), 400
    return 'OK'

# 處理收到的文字消息
@handler.add(MessageEvent, message=TextMessage)
def handle_text_message(event):
    text = event.message.text
    user_id = event.source.user_id

    if user_states.get(user_id) == "Reminders":
        formatted_time = parse_time("現在")
        response = openai.ChatCompletion.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "你是一個有用的提醒功能機器人，幫助用戶記錄需提醒的事情"},
                {"role": "user", "content": f"請把以下提醒的事項整理成Time和Content，時間格式為 YYYY-MM-DD HH:MM，並以Database語法存入，只需要寫語法就好，不需要額外補充而且時間一定要準確：現在時間是：{formatted_time},内容是{text}"}
            ]
        )
        response_text = response['choices'][0]['message']['content']
        line_bot_api.reply_message(event.reply_token, TextSendMessage(text=response_text))
        user_states[user_id] = ""

    elif text == "請輸入會議音檔" and user_states.get(user_id) not in ["Recording", "Reminders"]:
        user_states[user_id] = "Recording"

    elif text == "請輸入需提醒事項" and user_states.get(user_id) not in ["Recording", "Reminders"]:
        user_states[user_id] = "Reminders"

# 處理收到的音頻消息
@handler.add(MessageEvent, message=AudioMessage)
def handle_audio_message(event):
    user_id = event.source.user_id
    message_id = event.message.id
    message_content = line_bot_api.get_message_content(message_id)

    # 保存音频到本地
    with tempfile.NamedTemporaryFile(suffix='.m4a', delete=False) as tf:
        tf.write(message_content.content)
        audio_path = tf.name

    try:
        # 將 .m4a 文件轉換為 .wav 文件
        wav_path = convert_to_wav(audio_path)

        # 使用本地語音轉文字方法將語音轉為文本
        transcript = transcribe_audio(wav_path)

        # 根據用戶狀態進行相應處理
        if user_states.get(user_id) == "Recording":
            summary = summarize_with_openai(transcript)
            line_bot_api.reply_message(event.reply_token, TextSendMessage(text=summary))
        elif user_states.get(user_id) == "Reminders":
            formatted_time = parse_time("現在")
            response = openai.ChatCompletion.create(
                model="gpt-3.5-turbo",
                messages=[
                    {"role": "system", "content": "你是一個有用的提醒功能機器人，幫助用戶記錄需提醒的事情"},
                    {"role": "user", "content": f"請把以下提醒的事項整理成Time和Content，時間格式為 YYYY-MM-DD HH:MM，並以Database語法存入，只需要寫語法就好，不需要額外補充而且時間一定要準確：現在時間是：{formatted_time},内容是{transcript}"}
                ]
            )
            response_text = response['choices'][0]['message']['content']
            line_bot_api.reply_message(event.reply_token, TextSendMessage(text=response_text))
        user_states[user_id] = ""

    except Exception as e:
        line_bot_api.reply_message(event.reply_token, TextSendMessage(text=f"抱歉，無法處理您的錄音。錯誤信息: {str(e)}"))

# 將 .m4a 轉換為 .wav 的函數
def convert_to_wav(audio_path):
    wav_path = audio_path.replace('.m4a', '.wav')
    try:
        subprocess.run(['ffmpeg', '-i', audio_path, wav_path], check=True)
        return wav_path
    except subprocess.CalledProcessError as e:
        raise Exception(f"音頻轉換失敗: {e}")

# 定義語音轉文字函數（使用 SpeechRecognition 庫）
def transcribe_audio(audio_path):
    recognizer = sr.Recognizer()
    try:
        with sr.AudioFile(audio_path) as source:
            audio = recognizer.record(source)
            transcript = recognizer.recognize_google(audio, language="zh-CN")
            return transcript
    except sr.UnknownValueError:
        return "無法識別音訊內容。"
    except sr.RequestError as e:
        return f"語音識別服務不可用: {e}"

# 使用 OpenAI 提取摘要
def summarize_with_openai(transcript):
    response = openai.ChatCompletion.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "system", "content": "你是一個有用的會議記錄助手，幫助用戶開會的重點進行記錄，列點給我，不要多說別的東西。"},
            {"role": "user", "content": f"請總結以下文本的重點：{transcript}"}
        ]
    )
    return response['choices'][0]['message']['content']

# 啟動 Flask 應用
if __name__ == "__main__":
    app.run(port=5000, debug=True)
